<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="alternate" type="application/rss+xml" href="/decision-making-sp25/blog/rss.xml" title="Deep Decision Making and Reinforcement Learning RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/decision-making-sp25/blog/atom.xml" title="Deep Decision Making and Reinforcement Learning Atom Feed"><title data-react-helmet="true">Syllabus | Deep Decision Making and Reinforcement Learning</title><meta data-react-helmet="true" property="og:title" content="Syllabus | Deep Decision Making and Reinforcement Learning"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://nyu-robot-learning.github.io//decision-making-sp25/syllabus"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><link data-react-helmet="true" rel="shortcut icon" href="/decision-making-sp25/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://nyu-robot-learning.github.io//decision-making-sp25/syllabus"><link data-react-helmet="true" rel="alternate" href="https://nyu-robot-learning.github.io//decision-making-sp25/syllabus" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://nyu-robot-learning.github.io//decision-making-sp25/syllabus" hreflang="x-default"><link rel="stylesheet" href="/decision-making-sp25/assets/css/styles.009dfec1.css">
<link rel="preload" href="/decision-making-sp25/assets/js/runtime~main.71a4fb75.js" as="script">
<link rel="preload" href="/decision-making-sp25/assets/js/main.29eb5927.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/decision-making-sp25/"><div class="navbar__logo"><img src="/decision-making-sp25/img/NYU.png" alt="Site Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/decision-making-sp25/img/NYU.png" alt="Site Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">CSCI-GA 3033-090: Deep Decision Making and Reinforcement Learning</b></a><a class="navbar__item navbar__link" href="/decision-making-sp25/logistics">Logistics</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/decision-making-sp25/syllabus">Syllabus</a><a class="navbar__item navbar__link" href="/decision-making-sp25/assignments">Assignments</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ðŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ðŸŒž</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper mdx-wrapper mdx-page"><main class="container container--fluid margin-vert--lg"><div class="row mdxPageWrapper_eQvw"><div class="col col--8"><h2 class="anchor anchorWithStickyNavbar_y2LR" id="course-content">Course Content<a aria-hidden="true" class="hash-link" href="#course-content" title="Direct link to heading">â€‹</a></h2><table><thead><tr><th align="left">Date</th><th align="left">Lectures</th><th align="left">Contents</th><th align="left">Readings</th></tr></thead><tbody><tr><td align="left">1/24</td><td align="left">Introduction to Decision Making</td><td align="left">Part 1: Intelligence and decision making <br> Part 2: What is this class about?</td><td align="left">1. <a href="https://wi.mit.edu/unusual-labmates-how-c-elegans-wormed-its-way-science-stardom" target="_blank" rel="noopener noreferrer">Unusual Labmates: how C. elegans wormed its way into science stardom</a>  <br> 2. <a href="https://www.dummies.com/book/academics-the-arts/science/neuroscience/neuroscience-for-dummies-2nd-edition-282419/" target="_blank" rel="noopener noreferrer">Neuroscience For Dummies</a> <br> 3. <a href="https://www.amazon.com/Brief-History-Intelligence-Humans-Breakthroughs/dp/0063286343" target="_blank" rel="noopener noreferrer">A Brief History of Intelligence: Evolution, AI, and the Five Breakthroughs That Made Our Brains</a></td></tr><tr><td align="left">1/31</td><td align="left">Supervised Learning for Decision Making</td><td align="left">Part 1: Training Neural Networks <br> Part 2: Variants of Behavior Cloning policies</td><td align="left">1. Behavior Cloning (ALVINN) <br> 2. Variational Autoencoder <br> 3. Generative Adversarial Networks <br> 4. Case study papers: VINN, RT-1, Dobb-E, Implicit BC, BeT, C-BeT, Diffusion Policy <br> 5. <a href="https://supervised-robot-learning.github.io/" target="_blank" rel="noopener noreferrer">Supervised Policy Learning for Real Robots</a></td></tr><tr><td align="left">2/7</td><td align="left">Tutorial: Supervised Learning for Decision Making</td><td align="left">Setting up decision making environments and model training</td><td align="left"><a href="https://drive.google.com/drive/folders/1izZY_IQr6vZY-EhP0avbH2nNxc2wXxA-?usp=sharing" target="_blank" rel="noopener noreferrer">Resources</a></td></tr><tr><td align="left">2/14</td><td align="left">Multi-Armed Bandits</td><td align="left">Part 1: Formalism for Bandit problem <br> Part 2: Algorithms for Bandit problems</td><td align="left">1. <a href="https://ianosband.com/2015/07/28/Beat-the-bandit.html" target="_blank" rel="noopener noreferrer">Can you beat the bandit?</a> <br> 2. <a href="https://learnforeverlearn.com/bandits/" target="_blank" rel="noopener noreferrer">Bayesian Bandit Explorer</a></td></tr><tr><td align="left">2/21</td><td align="left">Guest Lecture: Mahi Shafiullah</td><td align="left">Examples of policy learning working in the real world</td><td align="left"></td></tr><tr><td align="left">2/28</td><td align="left">Markov Decision Process and simple RL methods</td><td align="left">Part 1: Motivation and formalism <br> Part 2: Core concepts of value and policy iteration</td><td align="left">Book: <a href="http://incompleteideas.net/book/the-book-2nd.html" target="_blank" rel="noopener noreferrer">Reinforcement Learning: An Introduction</a></td></tr><tr><td align="left">3/7</td><td align="left">Q-learning: from Tables to Atari</td><td align="left">Part 1: Why Q function? <br> Part 2: Deep Q functions: What goes wrong and how to make them work? <br> Part 3: Variants of DQN</td><td align="left"></td></tr><tr><td align="left">3/14</td><td align="left">Policy Optimization</td><td align="left">Part 1: MC-based optimization (CEM) <br> Part 2: Differentiable versions (REINFORCE) <br> Part 3: Trust region / proximal policy optimization</td><td align="left"></td></tr><tr><td align="left">3/21</td><td align="left">Tutorial: Visual and Temporal Policy Learning</td><td align="left"></td><td align="left"></td></tr><tr><td align="left">3/28</td><td align="left">SPRING BREAK</td><td align="left"></td><td align="left"></td></tr><tr><td align="left">4/4</td><td align="left">Guest Lecture: TBD</td><td align="left"></td><td align="left"></td></tr><tr><td align="left">4/11</td><td align="left">Decision Making with World Models</td><td align="left">Part 1: Classical approaches (LQR / iLQR / DDP) <br> Part 2: Model-based RL <br> Part 3: case study: Dreamer v3</td><td align="left"></td></tr><tr><td align="left">4/18</td><td align="left">Decision Making with Tree Search</td><td align="left">MCTC (AlphaGo, AlphaZero)</td><td align="left"></td></tr><tr><td align="left">4/25</td><td align="left">Revisiting Decision Making with Expert Data</td><td align="left">Inverse RL and offline RL</td><td align="left"></td></tr><tr><td align="left">5/2</td><td align="left">Course Project Presentations</td><td align="left"></td><td align="left"></td></tr></tbody></table></div><div class="col col--2"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#course-content" class="table-of-contents__link toc-highlight">Course Content</a></li></ul></div></div></div></main></div></div>
<script src="/decision-making-sp25/assets/js/runtime~main.71a4fb75.js"></script>
<script src="/decision-making-sp25/assets/js/main.29eb5927.js"></script>
</body>
</html>